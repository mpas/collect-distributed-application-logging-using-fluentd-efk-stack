# input forward plugin
<source>
  @type forward
  port 24224
  bind 0.0.0.0
</source>

<source>
  @type tail
  path /fluentd/etc/logs/custom-log.log
  format none
  tag intail
  refresh_interval 1s
</source>

# filter httd access logs
<filter httpd.access>
  @type parser
  format /^(?<host>[^ ]*) [^ ]* (?<user>[^ ]*) \[(?<time>[^\]]*)\] "(?<method>\S+)(?: +(?<path>[^ ]*) +\S*)?" (?<code>[^ ]*) (?<size>[^ ]*)(?: "(?<referer>[^\"]*)" "(?<agent>[^\"]*)")?$/
  time_format %d/%b/%Y:%H:%M:%S %z
  key_name log
  reserve_data true
</filter>

<filter springboot.**>
    @type parser
    key_name log
    reserve_data true
    reserve_time true
    <parse>
      @type grok
      grok_failure_key grokfailure
      <grok>
        pattern %{TIMESTAMP_ISO8601:time_stamp}%{SPACE}%{LOGLEVEL:log_level}%{SPACE}%{NUMBER:pid}%{SPACE}---%{SPACE}\[\s*%{DATA:threadname}\]%{SPACE}%{DATA:logger}%{SPACE}:%{SPACE}(?<message>(.|\r|\n)*)
      </grok>
    </parse>
</filter>

<filter springboot.**>
    @type record_transformer
    enable_ruby
    <record>
        @timestamp ${ require 'date'; DateTime.parse(record["time_stamp"]).iso8601(3) }
    </record>
</filter>


<match **>
  @type copy
  <store>
    @type stdout
  </store>  
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200    
    flush_interval 5

    logstash_format true
    include_tag_key true
  </store>
  <store>
    @type file
    path /fluentd/etc/logs/
  </store>
</match>